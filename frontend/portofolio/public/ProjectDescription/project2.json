{
    "title": "Using Head Movements to Predict Performance and Early Quitting in Virtual Reality",
    "media": [
        "/img/Waddle/1.jpg",
        "/img/Waddle/2.png",
        "/img/Waddle/3.png",
        "/img/Waddle/4.png",
        "/img/Waddle/5.png"
    ],
    "subtitles": [
        {
            "title": "Project Description",
            "content": "This project builds interpretable early-quit detectors from VR head-movement telemetry. We extract quaternion-based head rotations (and positions when available) from gameplay logs, convert them to per-frame Euler deltas, and segment the stream into direction-consistent intervals in yaw, pitch, and roll. These interval durations and movement magnitudes are then binned on power-of-two time scales to produce length-invariant histograms of “how often” and “how long” different kinds of head turns occur. Using these features, we construct balanced session-level datasets in HDF5 and train group-aware classifiers (Random Forest, XGBoost, Logistic Regression) to distinguish completing vs. quitting sessions, with t-tests, simple hand-crafted detectors, SHAP, and partial-dependence plots used to interpret which rotation patterns are most predictive."
        },
        {
            "title": "My Responsibility",
            "content": "I led the end-to-end modeling side of the project: implementing the head-rotation feature pipeline, constructing balanced session-level datasets (quit vs. non-quit), training and comparing multiple classifiers (Random Forest, XGBoost, Logistic Regression), and running SHAP/interpretability analyses to identify which movement patterns distinguish finishing players from early quitters."
        },
        {
            "title": "Tech Stack",
            "content": "Python, NumPy, pandas, SciPy, scikit-learn, XGBoost, h5py (HDF5), matplotlib"
        }
    ]
}